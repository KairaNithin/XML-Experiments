{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code mixed Data Creation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZhwXGwwK23nZ2lujcCKIzdIAoKuCpYFq",
      "authorship_tag": "ABX9TyNEszShxUarzpHm6JfE/PXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KairaNithin/XML-Experiments/blob/main/code_mixed_Data_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR36Gc6QX4pt"
      },
      "source": [
        "import csv\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twMH358yX-kO",
        "outputId": "d6fb56f4-9bcc-42b4-ca1b-aabe74bd842a"
      },
      "source": [
        "!pip install ekphrasis\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "# to leverage word statistics from Twitter\n",
        "seg_tw = Segmenter(corpus = \"twitter\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ekphrasis in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (6.0.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (0.4.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.5)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.0.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.41.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y4sGROgYC7S",
        "outputId": "0db9fa12-4fdc-4cd6-eba8-19bba2ed0298"
      },
      "source": [
        "!pip install tweet-preprocessor\n",
        "import preprocessor as tweet_proc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpSGnyawYKDq",
        "outputId": "80b65ced-a4a2-4912-9161-2752c7da5178"
      },
      "source": [
        "!pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5j2o1TYN0X"
      },
      "source": [
        "def make_list(proc_obj):\n",
        "  if proc_obj == None:\n",
        "    return []\n",
        "  \n",
        "  store = []\n",
        "  for unit in proc_obj:\n",
        "    store.append(unit.match)\n",
        "  \n",
        "  return store"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5dGvEglYWp9"
      },
      "source": [
        "def emotext(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\", \"\").replace(\":\", \"\").split()))\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kv8NhukYZUz"
      },
      "source": [
        "tweets = []\n",
        "raw_tweet_texts = []\n",
        "\n",
        "tweet_ids = []\n",
        "\n",
        "hashtags = []\n",
        "smileys = []\n",
        "emojis = []\n",
        "urls = []\n",
        "mentions = []\n",
        "numbers = []\n",
        "reserveds = []\n",
        "\n",
        "task_1_labels = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDc0EqtZaKGc"
      },
      "source": [
        "import pandas as pd\n",
        "hi_en_df = pd.read_csv(\"hindi_english.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thXedjp4aR3E"
      },
      "source": [
        "for i in range(len(hi_en_df)):\n",
        "\n",
        "    if hi_en_df['task1'][i] == \"no\":\n",
        "        task_1_labels.append(\"NOT\")\n",
        "        tweets.append(hi_en_df['text'][i])\n",
        "        raw_tweet_texts.append(tweet_proc.clean(hi_en_df['text'][i]))\n",
        "\n",
        "        parse_obj = tweet_proc.parse(hi_en_df['text'][i])\n",
        "\n",
        "        hashtags.append(make_list(parse_obj.hashtags))\n",
        "        smileys.append(make_list(parse_obj.smileys))\n",
        "        emojis.append(make_list(parse_obj.emojis))\n",
        "        urls.append(make_list(parse_obj.urls))\n",
        "        mentions.append(make_list(parse_obj.mentions))\n",
        "        numbers.append(make_list(parse_obj.numbers))\n",
        "        reserveds.append(make_list(parse_obj.reserved))\n",
        "        tweet_ids.append(i)\n",
        "\n",
        "    if hi_en_df['task1'][i] == \"yes\":\n",
        "      task_1_labels.append(\"HOF\")\n",
        "      tweets.append(hi_en_df['text'][i])\n",
        "      raw_tweet_texts.append(tweet_proc.clean(hi_en_df['text'][i]))\n",
        "\n",
        "      parse_obj = tweet_proc.parse(hi_en_df['text'][i])\n",
        "\n",
        "      hashtags.append(make_list(parse_obj.hashtags))\n",
        "      smileys.append(make_list(parse_obj.smileys))\n",
        "      emojis.append(make_list(parse_obj.emojis))\n",
        "      urls.append(make_list(parse_obj.urls))\n",
        "      mentions.append(make_list(parse_obj.mentions))\n",
        "      numbers.append(make_list(parse_obj.numbers))\n",
        "      reserveds.append(make_list(parse_obj.reserved))\n",
        "      tweet_ids.append(i)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd9aZyCia2XB"
      },
      "source": [
        "emoji_texts = []\n",
        "\n",
        "for emo_list in emojis:\n",
        "  texts = []\n",
        "  for emoji in emo_list:\n",
        "    text = emotext(emoji)\n",
        "    texts.append(text)\n",
        "  emoji_texts.append(texts)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzetG8TKbLDw"
      },
      "source": [
        "segmented_hashtags = []\n",
        "\n",
        "for hashset in hashtags:\n",
        "  segmented_set = []\n",
        "  for tag in hashset:\n",
        "    word = tag[1: ]\n",
        "    # removing the hash symbol\n",
        "    segmented_set.append(seg_tw.segment(word))\n",
        "  segmented_hashtags.append(segmented_set)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhcxpHkIbkVJ"
      },
      "source": [
        "import pickle\n",
        "name = 'hi_en_train.pickle'\n",
        "dickie = {}\n",
        "dickie['tweet_id'] = tweet_ids\n",
        "dickie['task_1'] = task_1_labels\n",
        "dickie['full_tweet'] = tweets\n",
        "dickie['tweet_raw_text'] = raw_tweet_texts\n",
        "dickie['hashtags'] = hashtags\n",
        "dickie['smiley'] = smileys\n",
        "dickie['emoji'] = emojis\n",
        "dickie['url'] = urls\n",
        "dickie['mentions'] = mentions\n",
        "dickie['numerals'] = numbers\n",
        "dickie['reserved_word'] = reserveds\n",
        "dickie['emotext'] = emoji_texts\n",
        "dickie['segmented_hash'] = segmented_hashtags\n",
        "\n",
        "\n",
        "\n",
        "with open(name, 'wb') as f:\n",
        "  pickle.dump(dickie, f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKyqak7deB6h"
      },
      "source": [
        "with open(\"hi_en_train.pickle\", 'rb') as f:\n",
        "    hi_en = pickle.load(f)\n",
        "hi_en = pd.DataFrame.from_dict(hi_en)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xstrbc5SixKQ",
        "outputId": "967e609c-6fd1-4365-ac10-8b303b0714df"
      },
      "source": [
        "hi_en"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>task_1</th>\n",
              "      <th>full_tweet</th>\n",
              "      <th>tweet_raw_text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>smiley</th>\n",
              "      <th>emoji</th>\n",
              "      <th>url</th>\n",
              "      <th>mentions</th>\n",
              "      <th>numerals</th>\n",
              "      <th>reserved_word</th>\n",
              "      <th>emotext</th>\n",
              "      <th>segmented_hash</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NOT</td>\n",
              "      <td>Knowing ki Vikas kitna samjhata hai Priyanka a...</td>\n",
              "      <td>Knowing ki Vikas kitna samjhata hai Priyanka a...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NOT</td>\n",
              "      <td>I am Muhajir .. Aur mere lye sab se Pehly Paki...</td>\n",
              "      <td>I am Muhajir .. Aur mere lye sab se Pehly Paki...</td>\n",
              "      <td>[#Muhajir, #Pakistani]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[ 10]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[muhajir, pakistani]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NOT</td>\n",
              "      <td>Doctor  sab sahi me ke PhD (in hate politics) ...</td>\n",
              "      <td>Doctor sab sahi me ke PhD (in hate politics) w...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[pic.twitter.com/fk1qUbQstw]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NOT</td>\n",
              "      <td>Poore Desh me Patel OBC me aate Hain sirf gujr...</td>\n",
              "      <td>Poore Desh me Patel OBC me aate Hain sirf gujr...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>HOF</td>\n",
              "      <td>Sarkar banne ke bad Hindu hit me ek bhi faisla...</td>\n",
              "      <td>Sarkar banne ke bad Hindu hit me ek bhi faisla...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4569</th>\n",
              "      <td>4573</td>\n",
              "      <td>NOT</td>\n",
              "      <td>ye attankwadi Indian agent hai jo terrorism ph...</td>\n",
              "      <td>ye attankwadi Indian agent hai jo terrorism ph...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4570</th>\n",
              "      <td>4574</td>\n",
              "      <td>NOT</td>\n",
              "      <td>bola na terrorism ko support karna band karoge...</td>\n",
              "      <td>bola na terrorism ko support karna band karoge...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4571</th>\n",
              "      <td>4575</td>\n",
              "      <td>NOT</td>\n",
              "      <td>lagta hai aap ne movie dekhi hai which is writ...</td>\n",
              "      <td>lagta hai aap ne movie dekhi hai which is writ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4572</th>\n",
              "      <td>4576</td>\n",
              "      <td>NOT</td>\n",
              "      <td>tum log terrorism ko support karna band kardo ...</td>\n",
              "      <td>tum log terrorism ko support karna band kardo ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4573</th>\n",
              "      <td>4577</td>\n",
              "      <td>HOF</td>\n",
              "      <td>mujhe pehele se hi pata tha so Sallu fans ke b...</td>\n",
              "      <td>mujhe pehele se hi pata tha so Sallu fans ke b...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4574 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tweet_id task_1  ... emotext        segmented_hash\n",
              "0            0    NOT  ...      []                    []\n",
              "1            1    NOT  ...      []  [muhajir, pakistani]\n",
              "2            2    NOT  ...      []                    []\n",
              "3            3    NOT  ...      []                    []\n",
              "4            4    HOF  ...      []                    []\n",
              "...        ...    ...  ...     ...                   ...\n",
              "4569      4573    NOT  ...      []                    []\n",
              "4570      4574    NOT  ...      []                    []\n",
              "4571      4575    NOT  ...      []                    []\n",
              "4572      4576    NOT  ...      []                    []\n",
              "4573      4577    HOF  ...      []                    []\n",
              "\n",
              "[4574 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnHAwo8bl6K0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}